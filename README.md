This is the repo for "[Language Models Lie and Detect Lies in Text-Based Games](https://docs.google.com/document/d/1rkfzRA-eiCJ5wuzNUTSyv7XhwGLO1buP5uWdiG3kL7E/edit?usp=sharing)". 

We've got a bunch of interesting results from watching language models play against each other. Now I'm building a website where people can play against language models and find out whether they can spot a language model's lies. Hopefully this will give us some interesting data and demonstrate that language models are capable not only of helpfulness and hallucination, but also deception. 

<img width="1512" alt="image" src="https://user-images.githubusercontent.com/78378219/221541877-db401a64-7774-4031-acc6-84509d5fb310.png">
